{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWOT hydrology products time series examples\n",
    "\n",
    "The Surface Water and Ocean Topography (SWOT) mission aims to provide valuable data and information about the world's oceans and its terrestrial surface water such as lakes, rivers, and wetlands. SWOT is being developed jointly by NASA and Centre National D'Etudes Spatiales (CNES), with contributions from the Canadian Space Agency (CSA) and United Kingdom Space Agency (UKSA). SWOT launched on the 16th of December of 2022 for its calibration-validation phase and entered its science 21-day repeat orbit in August 2023. More information can be found on [PO.DAAC SWOT website](https://podaac.jpl.nasa.gov/SWOT).\n",
    "\n",
    "This notebook shows how to create and export time series of SWOT hydrology parameters for [river](https://podaac.jpl.nasa.gov/dataset/SWOT_L2_HR_RiverSP_2.0) and [lake](https://podaac.jpl.nasa.gov/dataset/SWOT_L2_HR_LakeSP_2.0) products. Additional information is available on the [SWOT Data User Handbook](https://www.earthdata.nasa.gov/s3fs-public/2024-06/D-109532_SWOT_UserHandbook_20240502.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import geopandas as gpd\n",
    "from io import StringIO\n",
    "from matplotlib import colormaps as cmaps\n",
    "import matplotlib.colors as mcolors\n",
    "from ipywidgets import Box, VBox, HBox, Label, HTML, Checkbox\n",
    "from ipyleaflet import Map, GeoJSON, LayerGroup, DrawControl, WidgetControl, basemap_to_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HydroFeature Class and Subclasses\n",
    "The `HydroFeature` class and its subclasses, `Lake` and `Reach`, are designed to manage and visualize hydrological data. By initializing these classes, we set up the infrastructure required for further analysis and visualization in the notebook. These classes allow us to interact with WFS and [Hydrocron API](https://podaac.github.io/hydrocron/overview.html), fetch relevant data, and perform operations such as querying time series data and displaying features on a map.\n",
    "\n",
    "**Key Methods:**\n",
    "\n",
    "- **`__init__(self, bbox)`**  \n",
    "  Initializes with a bounding box (`bbox`) and sets up the WFS URL. Placeholder attributes such as `type_name`, `id_field`, and `feature` are initialized for subclass-specific values.\n",
    "\n",
    "- **`get_features(self)`**  \n",
    "  Fetches features from the [Prior River Database SWORD](https://catalogue.theia.data-terra.org/meta/SWOT_PRIOR_RIVER_DATABASE) or the [Prior Lake Database (PLD)](https://catalogue.theia.data-terra.org/meta/SWOT_PRIOR_LAKE_DATABASE) through a WFS request based on a bounding box.\n",
    "\n",
    "- **`query_hydrocron(self, query_url, feature_id, start_time, end_time, fields)`**  \n",
    "  Queries the Hydrocron API for time series data of the features identified in the area of interest, returning a list of data frames containing the queried data.\n",
    "\n",
    "**Subclasses**\n",
    "\n",
    "**`Lake` Class**  \n",
    "Inherits from `HydroFeature`. Tailored for handling lake-specific features. Initializes with attributes specific to lakes, such as `type_name`, `id_field`, and `feature`.\n",
    "\n",
    "**`Reach` Class**  \n",
    "Inherits from `HydroFeature`. Designed for handling river reach features. Sets attributes specific to rivers, including `type_name`, `id_field`, and `feature`.\n",
    "\n",
    "#### Using the [Hydrocron API](https://podaac.github.io/hydrocron/overview.html) to query time series data\n",
    "\n",
    "[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.13381966.svg)](https://doi.org/10.5281/zenodo.13381966)\n",
    "\n",
    "Hydrocron is an API that repackages hydrology datasets from the Surface Water and Ocean Topography (SWOT) satellite into formats that make time-series analysis easier.\n",
    "\n",
    "SWOT data is archived as individually timestamped shapefiles, which would otherwise require users to perform multiple file IO operations per river or lake feature to view the data as a timeseries. Hydrocron makes this possible with a single API call, facilitating creating analysis ready dataframes of the hydrological parameters from the [SWOT Level 2 River Single-Pass Vector Data Product](https://podaac.jpl.nasa.gov/dataset/SWOT_L2_HR_RiverSP_2.0) and the [SWOT Level 2 Lake Single-Pass Vector Data Product](https://podaac.jpl.nasa.gov/dataset/SWOT_L2_HR_LakeSP_2.0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HydroFeature:\n",
    "    def __init__(self, bbox):\n",
    "        self.wfs_url = \"https://hydroweb.next.theia-land.fr/geoserver/REF_DATA/ows\"\n",
    "        self.bbox = bbox\n",
    "        self.type_name = None\n",
    "        self.id_field = None\n",
    "        self.feature = None\n",
    "\n",
    "    def get_features(self):\n",
    "        \"\"\"Fetch features from a WFS service using a bounding box.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple: (list, GeoDataFrame) - List of IDs and GeoDataFrame of the features\n",
    "        \"\"\"\n",
    "        if self.bbox is None:\n",
    "            raise ValueError(\"Bounding box (bbox) is not defined.\")\n",
    "        \n",
    "        # Format bbox parameter for the WFS request\n",
    "        bbox_str = f\"{self.bbox[0]},{self.bbox[1]},{self.bbox[2]},{self.bbox[3]},EPSG:4326\"\n",
    "        \n",
    "        # Parameters for GetFeature request\n",
    "        params = {\n",
    "            \"service\": \"WFS\",\n",
    "            \"version\": \"2.0.0\",\n",
    "            \"request\": \"GetFeature\",\n",
    "            \"typeName\": self.type_name,  # Layer name set by subclass\n",
    "            \"outputFormat\": \"application/json\",  # Requesting the response in JSON format\n",
    "            \"bbox\": bbox_str  # Bounding box\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Send the request\n",
    "            response = requests.get(self.wfs_url, params=params)\n",
    "            \n",
    "            # Check if the request was successful\n",
    "            response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "            \n",
    "            # Parse the response as JSON\n",
    "            feature_info = response.json()\n",
    "            \n",
    "            # Extract IDs from features based on the id_field\n",
    "            ids = [feature['id'].split('.')[-1] for feature in feature_info['features']]\n",
    "            \n",
    "            # Convert JSON features to GeoDataFrame\n",
    "            gdf = gpd.GeoDataFrame.from_features(feature_info['features'])\n",
    "            \n",
    "            return ids, gdf\n",
    "        \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return [], gpd.GeoDataFrame()\n",
    "        \n",
    "    def visualize_features(self, gdf):\n",
    "        \"\"\"Visualize hydrological features on a map with checkboxes for toggling visibility.\"\"\"\n",
    "        if gdf.empty:\n",
    "            print(\"No features to display.\")\n",
    "            return\n",
    "        \n",
    "        # Center the map around the bounding box center\n",
    "        bounds = gdf.total_bounds  # [minx, miny, maxx, maxy]\n",
    "        center = [(bounds[1] + bounds[3]) / 2, (bounds[0] + bounds[2]) / 2]  # (lat, lon)\n",
    "        m = Map(center=center, zoom=9, scroll_wheel_zoom=True)\n",
    "\n",
    "        # Layer group to hold all GeoJSON layers\n",
    "        layer_group = LayerGroup()\n",
    "\n",
    "        # Generate a color map\n",
    "        cmap = cmaps.get_cmap('tab10').resampled(len(gdf))\n",
    "\n",
    "        # Add each feature as a separate GeoJSON layer with color-coded checkboxes\n",
    "        checkboxes = []\n",
    "        for i, feature in enumerate(gdf.iterfeatures()):\n",
    "            feature_id = feature['properties'].get(self.id_field)\n",
    "            color = mcolors.to_hex(cmap(i))\n",
    "            geojson_layer = GeoJSON(data=feature, style={'color': color, 'weight': 2})\n",
    "            layer_group.add_layer(geojson_layer)\n",
    "\n",
    "            # Create a colored square and checkbox with ID\n",
    "            color_square = f\"<div style='width: 15px; height: 15px; background-color: {color}; display: inline-block;'></div>\"\n",
    "            checkbox = Checkbox(value=True, indent=False)\n",
    "\n",
    "            # Combine the colored square, checkbox, and feature ID into a single label\n",
    "            label = f\"<div style='display: inline-block; vertical-align: middle; margin-left: 5px; width: 100px'>{color_square} {feature_id}</div>\"\n",
    "\n",
    "            # Use HBox to place the checkbox and label next to each other\n",
    "            checkbox_with_color = HBox([HTML(value=label), checkbox], layout={\n",
    "                'display': 'flex',        # Flexbox layout to keep items in a row\n",
    "                'align-items': 'center',  # Vertically center items within the HBox\n",
    "                'width': '140px',         # Width to fit content\n",
    "            })\n",
    "                \n",
    "            checkboxes.append((checkbox, geojson_layer, checkbox_with_color))\n",
    "\n",
    "        # Add the layer group to the map\n",
    "        m.add_layer(layer_group)\n",
    "\n",
    "        # Function to toggle layers on checkbox change\n",
    "        def toggle_layer(change, layer):\n",
    "            layer.visible = change['new']\n",
    "\n",
    "        # Attach the toggle functionality to each checkbox\n",
    "        checkbox_widgets = []\n",
    "        for checkbox, layer, checkbox_with_color in checkboxes:\n",
    "            checkbox.observe(lambda change, layer=layer: toggle_layer(change, layer), 'value')\n",
    "            checkbox_widgets.append(checkbox_with_color)\n",
    "\n",
    "        # Create a VBox for checkboxes to toggle layers and add it to the top-right corner\n",
    "        checkbox_vbox = VBox(checkbox_widgets, layout={\n",
    "            'overflow_y': 'scroll',   # Enable vertical scrolling\n",
    "            'display': 'flex',        # Flexbox layout to keep items in a column\n",
    "            'align-items': 'center',  # Vertically center items within the VBox\n",
    "            'padding': '5px',         # Add some padding inside the box\n",
    "            'border': '1px solid black',  # Optional: Add a border around the checkbox container\n",
    "            'width': '160px',         # Fixed width for the checkbox container\n",
    "        })\n",
    "        checkbox_control = WidgetControl(widget=checkbox_vbox, position='topright')\n",
    "        m.add_control(checkbox_control)\n",
    "\n",
    "        # Display the map\n",
    "        display(m)\n",
    "\n",
    "    def query_hydrocron(self, query_url, feature_id, start_time, end_time, fields):\n",
    "        \"\"\"Query Hydrocron for reach/lake-level time series data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        query_url : str\n",
    "            URL to use to query FTS.\n",
    "        feature_id : str\n",
    "            Identifier for the feature (reach_id or lake_id).\n",
    "        start_time : str\n",
    "            Time to start query (ISO format).\n",
    "        end_time : str\n",
    "            Time to end query (ISO format).\n",
    "        fields : str\n",
    "            Comma-separated list of fields to return in query response.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            DataFrame containing query results.\n",
    "        \"\"\"\n",
    "        \n",
    "        params = {\n",
    "            \"feature\": self.feature,  # Dynamically set based on subclass\n",
    "            \"feature_id\": feature_id,\n",
    "            \"output\": \"csv\",\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time,\n",
    "            \"fields\": fields\n",
    "        }\n",
    "        results = requests.get(query_url, params=params)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if results.status_code == 200:\n",
    "            print(f\"Success: Retrieved data for {self.feature} ID {feature_id}\")\n",
    "            if \"results\" in results.json().keys():\n",
    "                results_csv = results.json()[\"results\"][\"csv\"]\n",
    "                df = pd.read_csv(StringIO(results_csv))\n",
    "            else:\n",
    "                df = self.create_empty_dataframe(feature_id)\n",
    "        else:\n",
    "            print(f\"Error: Unable to retrieve data for {self.feature} ID {feature_id}, status code {results.status_code}\")\n",
    "            print(results.json())\n",
    "            df = self.create_empty_dataframe(feature_id)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_empty_dataframe(self, feature_id):\n",
    "        \"\"\"Create an empty DataFrame for cases where no data is returned for a feature identifier.\"\"\"\n",
    "        empty_df = pd.DataFrame({\n",
    "            self.id_field: np.int64(feature_id),\n",
    "            \"time_str\": datetime.datetime(1900, 1, 1).strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "            \"wse\": -999999999999.0,\n",
    "            \"wse_units\": \"m\"\n",
    "        }, index=[0])\n",
    "        return empty_df\n",
    "    \n",
    "    def plot_results(self, results):\n",
    "        \"\"\"\n",
    "        Plot the results of a set of time series data for multiple reach/lake identifiers.\n",
    "\n",
    "        Parameters:\n",
    "        - results (list of pandas.DataFrame): A list of DataFrames containing time series data for each identifier.\n",
    "\n",
    "        Returns:\n",
    "        - combined_plot (hvplot object): A combined plot of line and scatter plots for each identifier,\n",
    "                                         with the x-axis representing time and the y-axis representing the water surface elevation.\n",
    "        \"\"\"\n",
    "        # Load DataFrame results into a single Pandas DataFrame\n",
    "        df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "        # Remove fill values for missing observations\n",
    "        df = df.loc[(df[\"wse\"] != -999999999999.0)]\n",
    "\n",
    "        # Convert time_str to datetime format\n",
    "        df.time_str = pd.to_datetime(df.time_str)\n",
    "\n",
    "        # Plot results\n",
    "        line_plot = df.hvplot(x=\"time_str\", y=\"wse\", by=self.id_field, kind=\"line\", persist=True)\n",
    "        line_plot.opts(xrotation=90, xlabel=\"Date\", ylabel=\"Water Surface Elevation (m)\")\n",
    "\n",
    "        scatter_plot = df.hvplot(x=\"time_str\", y=\"wse\", by=self.id_field, kind=\"scatter\", persist=True)\n",
    "        combined_plot = line_plot * scatter_plot\n",
    "\n",
    "        return combined_plot\n",
    "\n",
    "class Lake(HydroFeature):\n",
    "    def __init__(self, bbox):\n",
    "        super().__init__(bbox)\n",
    "        self.type_name = \"swot_prior_lake_db\"  # Lake specific type name\n",
    "        self.id_field = \"lake_id\"  # Field to extract IDs for lakes\n",
    "        self.feature = \"PriorLake\"\n",
    "\n",
    "class Reach(HydroFeature):\n",
    "    def __init__(self, bbox):\n",
    "        super().__init__(bbox)\n",
    "        self.type_name = \"swot_prior_river_db\"  # River specific type name\n",
    "        self.id_field = \"reach_id\"  # Field to extract IDs for rivers\n",
    "        self.feature = \"Reach\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define your bounding box\n",
    "Define your bounding box by drawing a rectangle to select the area of interest. `bbox` is a global variable and it is automatically updated to reflect the coordinates of the selected area. This bounding box will be used to fetch and analyze features within the specified geographic region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Map(center=(52.1326, 5.2913), zoom=4, scroll_wheel_zoom=True)\n",
    "\n",
    "# Add a drawing control to the map\n",
    "draw_control = DrawControl()\n",
    "\n",
    "# Set drawing mode to rectangle\n",
    "draw_control.rectangle = {\n",
    "    \"shapeOptions\": {\n",
    "        \"color\": \"#ff0000\",\n",
    "        \"weight\": 4\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add the draw control to the map\n",
    "m.add_control(draw_control)\n",
    "\n",
    "# Widget to display bounding box coordinates\n",
    "coords_label = Label()\n",
    "\n",
    "bbox=None\n",
    "# Callback function to capture and display bounding box coordinates\n",
    "def handle_draw(self, action, geo_json):\n",
    "    global bbox\n",
    "    coords = geo_json['geometry']['coordinates'][0]\n",
    "    min_lon, min_lat = coords[0]  # Southwest corner\n",
    "    max_lon, max_lat = coords[2]  # Northeast corner\n",
    "    bbox = (min_lon, min_lat, max_lon, max_lat)\n",
    "    coords_label.value = f\"bbox = {bbox}\"\n",
    "\n",
    "# Bind the callback function to the draw event\n",
    "draw_control.on_draw(handle_draw)\n",
    "\n",
    "# Display the map and coordinates\n",
    "display(VBox([m, coords_label]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### River Example\n",
    "Using a WFS on the [SWOT Prior River Database SWORD](https://catalogue.theia.data-terra.org/meta/SWOT_PRIOR_RIVER_DATABASE) available through the Theia Data and Services centre for continental surfaces catalogue, extracting the reach IDs within your area of interest. \n",
    "\n",
    "The SWOT Prior River Database SWORD dataset provides high-resolution river nodes (200 m) and reaches (~10 km) with attached hydrologic variables (water surface elevation, width, slope, etc.) as well as a consistent topological system for global rivers 100 m wide and greater. The dataset combines multiple global river- and satellite-related datasets to define the nodes and reaches used in the [SWOT Level 2 River Single-Pass Vector Data Product](https://podaac.jpl.nasa.gov/dataset/SWOT_L2_HR_RiverSP_2.0). See the [Product Description Document](http://gaia.geosci.unc.edu/SWORD/SWORD_ProductDescription_v16.pdf) and [Altenau et al. (2021)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021WR030054) for additional information. The latest release of SWORD may be explored and downloaded on the [dedicated dashboard](https://www.swordexplorer.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Reach subclass to get river features\n",
    "river = Reach(bbox)\n",
    "reach_ids, river_gdf = river.get_features() \n",
    "\n",
    "# Print and visualize the reach IDs as characterized in the SWORD database\n",
    "print(\"List of river reach IDs:\")\n",
    "print(reach_ids)\n",
    "\n",
    "river.visualize_features(river_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hydrological parameters from the [SWOT Level 2 River Single-Pass Vector Data Product](https://podaac.jpl.nasa.gov/dataset/SWOT_L2_HR_RiverSP_2.0) as described in the documentation can be modified in *fields*, with data field requests described in the [Hydrocron API endpoints](https://podaac.github.io/hydrocron/timeseries.html#request-parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to start the query to the Hydrocron API\n",
    "HYDROCRON_URL = \"https://soto.podaac.earthdatacloud.nasa.gov/hydrocron/v1/timeseries\"\n",
    "start_time = \"2023-02-01T00:00:00Z\" \n",
    "end_time = \"2024-09-01T00:00:00Z\"\n",
    "fields = \"reach_id,time_str,wse,wse_u,reach_q,slope,width,river_name,geometry,dschg_c\" # Adjust for your parameters of interest\n",
    "\n",
    "# Query for river reach data\n",
    "river_results = []\n",
    "for reach in reach_ids:\n",
    "    river_df = river.query_hydrocron(HYDROCRON_URL, reach, start_time, end_time, fields)\n",
    "    river_results.append(river_df)\n",
    "\n",
    "# Visualize Water Surface Elevation (WSE)\n",
    "river.plot_results(river_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, df in enumerate(river_results):\n",
    "    # Extract the reach_id to use as part of the filename\n",
    "    reach_id = df['reach_id'].iloc[0]\n",
    "    \n",
    "    # Define a file name using the reach_id\n",
    "    file_name = f\"timeSeries_reach{reach_id}.csv\"\n",
    "    \n",
    "    # Export DataFrame to CSV\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print(f\"DataFrame for reach_id {reach_id} exported to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lake Example\n",
    "Using a WFS on the [SWOT Prior Lake Database](https://catalogue.theia.data-terra.org/meta/SWOT_PRIOR_LAKE_DATABASE) available through the Theia Data and Services centre for continental surfaces catalogue, extracting the lake IDs within your area of interest. \n",
    "\n",
    "The SWOT Prior Lake Database dataset provides a global inventory of lakes and reservoirs with polygons and other useful metadata. The database provides prior data on known lakes, making it possible to link SWOT lake observations over time and to compute storage change.\n",
    "\n",
    "It is generated by combining multiple global and regional hydrographic databases into one congruent product. The current version is mainly based on the CIRCA-2015 (Copyright UCLA) lake water extent map but relies also on several other datasets, including the *SWOT Prior River Database SWORD* which is therefore compatible. It is used to generate key hydrology parameters in the [SWOT Level 2 Lake Single-Pass Vector Data Product](https://podaac.jpl.nasa.gov/dataset/SWOT_L2_HR_LakeSP_2.0). For further information visit the [Auxiliary Data Description Document](https://hydroweb.next.theia-land.fr/docs/collections/resources/swot/SWOT-IS-CDM-1944-CNES_AuxData_LakeDatabase_20231208_RevB_signed.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Lake subclass to get lake features\n",
    "lake = Lake(bbox)\n",
    "lake_ids, lake_gdf = lake.get_features()\n",
    "\n",
    "# Print and visualize the lake IDs as characterized in the Prior Lake Database\n",
    "print(\"List of lake IDs:\")\n",
    "print(lake_ids)\n",
    "\n",
    "lake.visualize_features(lake_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hydrological parameters from the [SWOT Level 2 Lake Single-Pass Vector Data Product](https://podaac.jpl.nasa.gov/dataset/SWOT_L2_HR_LakeSP_2.0) as described in the documentation can be modified in *fields*, with data field requests described in the [Hydrocron API endpoints](https://podaac.github.io/hydrocron/timeseries.html#request-parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create queries that return Pandas.DataFrame objects\n",
    "HYDROCRON_URL = \"https://soto.podaac.earthdatacloud.nasa.gov/hydrocron/v1/timeseries\"\n",
    "start_time = \"2023-02-01T00:00:00Z\"\n",
    "end_time = \"2024-08-24T00:00:00Z\"\n",
    "fields = \"lake_id,time_str,wse,wse_u,area_total,quality_f,lake_name\"\n",
    "lake_results = []\n",
    "for i in lake_ids:\n",
    "    lake_df = lake.query_hydrocron(HYDROCRON_URL, i, start_time, end_time, fields)\n",
    "    lake_results.append(lake_df)\n",
    "    \n",
    "lake.plot_results(lake_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, df in enumerate(lake_results):\n",
    "    # Extract the lake_id to use as part of the filename\n",
    "    lake_id = df['lake_id'].iloc[0] \n",
    "    \n",
    "    # Define a file name using the reach_id\n",
    "    file_name = f\"timeSeries_lake{lake_id}.csv\"\n",
    "    \n",
    "    # Export DataFrame to CSV\n",
    "    df.to_csv(file_name, index=False)\n",
    "    print(f\"DataFrame for lake_id {lake_id} exported to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further tutorials on SWOT data and its capabilities can be found in the [SWOT Data Tutorials by PO.DAAC](https://podaac.github.io/tutorials/quarto_text/SWOT.html) and in the [SWOT Community Repository](https://swot-community.github.io/SWOT-galleries/).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SWOT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
